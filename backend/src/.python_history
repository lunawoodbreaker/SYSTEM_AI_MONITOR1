from datasets import load_dataset
ds = load_dataset("c4", "en", split="train[:1024]")
ds.save_to_disk("C:\\Users\\Luna\\Desktop\\Mymodel")
from datasets import load_dataset
ds = load_dataset("c4", "en", split="train[:1024]", trust_remote_code=True)
ds.save_to_disk("C:\\Users\\Luna\\Desktop\\Mymodel")
from datasets import load_dataset
ds = load_dataset("json", data_files=[
    "C:\\Users\\Luna\\Desktop\\Mymodel\\c4-train.00001-of-01024.json.gz",
        "C:\\Users\\Luna\\Desktop\\Mymodel\\c4-train.00002-of-01024.json.gz",
            "C:\\Users\\Luna\\Desktop\\Mymodel\\c4-train.00003-of-01024.json.gz",
                # Add more up to the last downloaded shard
                ])
ds.save_to_disk("C:\\Users\\Luna\\Desktop\\Mymodel")
exi
from datasets import load_dataset
ds = load_dataset("c4", "en", split="train[:1024]", trust_remote_code=True)
print(ds.info)
pip install datasets
import datasets
print(datasets.__version__)  # Should print the installed version
from datasets import load_dataset
ds = load_dataset("c4", "en", split="train[:1024]", trust_remote_code=True)
print(ds.info)
from datasets import load_dataset
ds = load_dataset("allenai/c4", "en", split="train[:1024]", trust_remote_code=True)
ds.save_to_disk("C:\\Users\\Luna\\Desktop\\Mymodel")
import json
with open("C:\\Users\\Luna\\Desktop\\Mymodel\\c4-train.00000-of-01024.json", "r", encoding="utf-8") as f:
        data = json.load(f)
        
import os
from datasets import load_dataset
# Define your dataset and destination folder
dataset_name = "allenai/c4"
subset = "en"
destination_folder = "C:\\Users\\Luna\\Desktop\\Mymodel"
# Ensure the destination folder is empty
if os.path.exists(destination_folder):
            for file in os.listdir(destination_folder):
                                file_path = os.path.join(destination_folder, file)
                                        os.remove(file_path)  # Remove existing files
                                        
# Download only 10% of the dataset (about 102 shards)
ds = load_dataset(dataset_name, subset, split="train[:10%]")
# Save the dataset to the destination
ds.save_to_disk(destination_folder)
print(f"Dataset saved successfully in {destination_folder}")
import os
from datasets import load_dataset
# Define the dataset and destination folder
dataset_name = "allenai/c4"
subset = "en"
destination_folder = "C:\\Users\\Luna\\Desktop\\Mymodel"
# Ensure the destination folder is empty before downloading
if os.path.exists(destination_folder):
                for file in os.listdir(destination_folder):
                                        file_path = os.path.join(destination_folder, file)
                                                os.remove(file_path)  # Remove old files
                                                
# Download approximately 1GB worth of data (about 3 shards)
ds = load_dataset(dataset_name, subset, split="train[:3]")  # Adjusted to only get 3 shards
# Save the dataset to the destination folder
ds.save_to_disk(destination_folder)
print(f"Dataset saved successfully in {destination_folder} with approx 1GB of data.")
from datasets import Dataset
import json
# Load JSONL
samples = []
with open(r"C:\Users\Luna\Desktop\Mymodel\Data\c4_subset.jsonl", 'r', encoding='utf-8') as f:
        for line in f:
                        samples.append(json.loads(line))
                        
# Convert to Dataset and save as Arrow
dataset = Dataset.from_list(samples)
dataset.save_to_disk(r"C:\Users\Luna\Desktop\Mymodel\Data\c4_subset")
print("Converted JSONL to Arrow format at C:\Users\Luna\Desktop\Mymodel\Data\c4_subset")
from datasets import load_from_disk
ds = load_from_disk(r"C:\Users\Luna\Desktop\Mymodel\Data\c4_subset")
print(f"Number of samples: {len(ds)}")
from transformers import AutoModelForCausalLM, AutoTokenizer
model_path = r"C:\Users\Luna\Desktop\Mymodel\Mistral\minitron-8b-instruct"
model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained(model_path)
from transformers import AutoModelForCausalLM, AutoTokenizer
model_path = r"C:\Users\Luna\Desktop\Mymodel\Mistral\minitron-8b-instruct"
model = AutoModelForCausalLM.from_pretrained(model_path, device_map="auto")
tokenizer = AutoTokenizer.from_pretrained(model_path)
from datasets import load_from_disk
dataset_path = "C:/Users/Luna/Desktop/Mymodel/Data/c4_subset"
ds = load_from_disk(dataset_path)
print(ds)  # Check if it loads correctly
pip install dataset
from datasets import load_from_disk
dataset_path = "C:/Users/Luna/Desktop/Mymodel/Data/c4_subset"
ds = load_from_disk(dataset_path)
print(ds)  # Check if it loads correctly
import os
print(os.getcwd())  # Shows where the script is running from
from datasets import load_from_disk
dataset_path = r"C:/Users/Luna/Desktop/Mymodel/Data/c4_subset"
ds = load_from_disk(dataset_path)
print(ds)
cd Desktop
import torch
# Load model directly
from transformers import AutoTokenizer, AutoModelForCausalLM
tokenizer = AutoTokenizer.from_pretrained("LoneStriker/NeuralHermes-2.5-Mistral-7B-8.0bpw-h8-exl2")
model = AutoModelForCausalLM.from_pretrained("LoneStriker/NeuralHermes-2.5-Mistral-7B-8.0bpw-h8-exl2")
cygwin_setup.txt
cygwin_setup
cygwin_setup.py
ls
dir
